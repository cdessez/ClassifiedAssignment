\documentclass[11pt,a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{array}
\usepackage{tabularx}
\usepackage[latin1]{inputenc}
\usepackage{mathtools}
\setlength{\topmargin}{-.5in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{.125in}
\setlength{\textwidth}{6.25in}
\begin{document}
\title{Parallel Algorithms Coursework}
\author{C\'edric DESSEZ, Valentin GRAND, Yann NICOLAS, Cyril NOVEL, Nicolas SERVEL}
\maketitle

\section{Gathering the clues}
The first thing we did was to analyze in depth the evidence given by our intel. Hopefully the engineers from Nukehavistan were kind enough to leave clues about the computer system.

The very first thing we did was to find the identity of the man portrayed on the system. We were able to process the face into the database of Interpol, hoping we will find a rogue scientist working for the Nukehavistan. Unfortunately no match were found. We then used the ReverseImages tool Q made for us and found that the man was \textit{Leonhard Euler}, portrayed on a 1957 stamp of the USSR. Such a link supposes that the Nukehavistan is a communist nation and so a major threat to the democracy all around the world.

Because of the link with the USSR, we assumed that the funny writing above the clock was in Cyrillic script. As no one in our team was able to understand russian, we contacted the Translation Service of the MI-6. The translation was \textit{fast inverter integrated functions}.

The text below the clock is in french. As we are french, we perfectly understood it and it means \textit{Made in France}. However, it is very unlikely this machine was produced in France. The final design is ugly and everyone knows French are all about beauty and class. We assumed this was only a trick to harden our research.

\begin{figure}[!h]
\centering
\includegraphics[width=5cm]{oss.png}
\caption{The model of the classy French spy}
\label{frenchspy}
\end{figure}

We then took a look to the two sets of coordinates. The set along the board points to the lovely village of \textit{Beaumont-en-Auge} in France. Among the famous people born in this town, one stands out. \textit{Pierre Simon de Laplace} was a mathematician and his work could have highly interested the Nukehavistan. The second coordinates confirmed our idea : it points near the \textit{Laplace} RER station in Paris. We don't believe in coincidence. Laplace's work is the key of the system. The power to the minus one on the second set of coordinates strengthens our assumption about the \textit{inverter}.

We finally called the technical hotline. Since it is a charged number, we joined the bill at the end of the report. The technical hotline is only an answerbot. We tested if it was telling the truth by asking it the answer to the Ultimate Question of Life, the Universe and Everything. Since it answered 42, we assumed the bot was powerful enough to answer our upcoming questions\footnote{This raises serious issues about the advanced level of Nukehavistan in the Computer Science field. Maybe we should applied for a PhD in their university.}. When we asked what was in the box, it said \textit{Numerical Inversion of Laplace Transforms of Probability Distributions}. A quick and efficient DuckDuckGo search -- we made sure we weren't tracked -- pointed us to a research paper from 1995, presenting an algorithm using the Euler method for inverting Laplace transforms.

The loop was almost complete. We knew what the algorithm was and what to code. The only thing we didn't know was what the program was actually doing. We tried to reverse engineer the \textit{mystery.o} file. We obtained some strange figures.

\begin{figure}[!h]
\centering
\includegraphics[width=10cm]{outputs.png}
\caption{Reverse engineering inputs and outputs.}
\label{reverse}
\end{figure}

We then made two assumptions. The first possibility is that the Nukehavistan is trying to communicate with superior life forces. The second possibility is that this computer system is prime in the job of the Nukehavistan spies. Since we are fierce scientists, we ruled out the first option. Thus we brainstormed over the second option by watching all the James Bond movies. At the end of this intensive marathon, we reached a conclusion :

\begin{figure}[!h]
\centering
\includegraphics[width=8cm]{watches.png}
\caption{Watches}
\label{reverse}
\end{figure}

Every spy needs a good watch! If we look closely to the computer system, the small peak of the output is on the 3 and the big peak is on the 11. The clock has its small hand pointing between 3 and 4 -- so in the 3 \textsuperscript{rd} hour. The large hand is pointing at 11. So the output of the computer system gives us the time!

\section{Implementation}

Since every good spy must be able to adapt and exploit their resources in the best possible way, they need a piece of software that is the fastest possible not only on an on-stage operation, but also when they are preparing the mission at the headquarters with access to the best super calculator in the world. This is why we have optimized this tremendous clock not only to run sequentially on a single machine, but also in parallel in several processes, multithreaded or not depending on the given option, distributed among a pool of machines.

\subsection{Sequential algorithm}

The first step in building this powerful clock is to implement and optimize the sequential algorithm. We first made a rough copy of the algorithm from the research paper and then modified it to make it more efficient and more flexible.\\

In the paper, the parameters \verb_N_ and \verb_M_ are hardcoded respectively to the values 15 and 11. That allow them to have a quite efficient processing and to hardcode the binomial coefficients. Those parameters determine the accuracy of the approximations done by the algorithm. After running a few tests, we realized that the more influent of those is \verb_N_ which we decided to set by default to $100$ (this also gives more computation to parallelize in the next steps). We have increased \verb_M_ a bit, up to $15$, to improve the accuracy, but also in anticipation of the parallelization which will use 16 machines.\\

In order to plot the inverted Laplace transform, we need to run this algorithm many times to obtain enough points. Thus we have strived to mutualise as much computation as possible. First the binomial coefficients are processed once and for all and saved to memory, as well as their sum which is in fact $2^M$ (hardcoded to $2048$ in the paper). Likewise, we process $exp(\frac{A}{2})$ only once for the whole set of points.\\

Besides, we have little interest here in the truncation error estimate, so we have got rid of the part of the code that processed it in the paper.\\

We have also merged the last two loops. As a matter of fact, filling an array \verb_SU_ with one loop to get \verb_Avgsu_ by summing its elements in a second loop is unefficient because we can do both at the same time which reduces the loop administration overhead and allows us to keep only a \verb_double_ variable instead of the array \verb_SU_.\\

We have also optimized the calculus of the variables \verb_i_ and \verb_Y_. In the paper they are computed with multiplications of float number, whereas there evolution corresponds to an incrementation by a fixed value at each iteration. Since in general an addition costs much less than a multiplication, this makes the loop faster. Notice there could be precision problems due to many successive foating point additions if \verb_M_ became much higher.\\

We are not sure whether or not those optimizations are substantial compared to the call to the mystery function, but it cannot do any harm anyways. Furthermore, since our class \verb_SeqLaplaceInv_ takes the function to invert as an argument, it might end up being useful to invert other functions less costly than our mystery function.

\subsection{Parallel MPI algorithm}

The program can be quite long when the size of the input increases. In order to accelerate what the machine does, we can use numerous processors in parallel. We call $N_p$ the number of processes. The program takes a vector of doubles as input, computes the algorithm for each data point and return a vector of doubles as output. We propose two different methods to parallelize the implementation:

\begin{itemize}

\item parallelizing the algorithm by rearranging the sequential algorithm,

\item dividing the input into chunks, and running in parallel the sequential algorithm on each chunk.

\end{itemize}

\subsubsection{Parallel version of the algorithm}

In the sequential version of the algorithm, we have numerous sums. We want to calculate these sums in parallel but the problem is that each term of each sum depends on previous sums and one or more other terms. In order to parallelize the algorithm we have to come up with steps that are independent from each other.

\subsubsection*{Maths behind the parallelization}

The calculation of $Fun$ is the part of the algorithm we want to parallelize.

\begin{eqnarray}
	sum &=& \frac{1}{2}   \sum_{i=1}^{Ntr} (-1)^{i}fnRf(X,iH)\\
	SU(1) &=& sum  \\
	SU(k + 1) &=& SU(K) + (-1)^{Ntr}fnRf(X,(Ntr + k)H) \label{SU(i)}\\
	Fun &=&\frac{U}{Ctot} \sum_{i=1}^{M+1} \binom{M}{i-1}SU(i) \label{Fun}
\end{eqnarray}

We first notice that we can easily calculate $sum$ in parallel by calculating each term in parallel and then sum them. However, each $SU(i)$ needs $SU(i-1)$ to be calculated, so we must determine $Fun$ otherwise to make the algorithm.
We can rewrite \eqref{SU(i)} this way :
\begin{equation}
	SU(k) = sum + \sum_{i=1}^{k-1} (-1)^{Ntr+k-1}fnRf(X,(Ntr + k-1)H)
	\label{rewrite SU}
\end{equation}
In this case there are some values of $fnRf$ that are used by many $SU$, so we lose time when we compute these expensive calculations more than once.
From \eqref{Fun} and \eqref{rewrite SU} we can rewrite a formulation for Fun :
\begin{equation}
	Fun =\displaystyle{ \frac{U}{Ctot}  \sum_{k=1}^{M+1} \binom{M}{k-1}\left(sum + \sum_{i=1}^{k-1} (-1)^{Ntr+k-1}fnRf(X,(Ntr + k-1)H)\right)}
	\label{Fun2}
\end{equation}
We can change \eqref{Fun2} into :
\begin{eqnarray}
	S(1) &=& sum\\
	S(k) &=& (-1)^{Ntr+k-1}fnRf(X,(Ntr + k-1)H)\\
	Fun &=& \displaystyle{U \sum_{k=1}^{M+1}\left(S(k)(1-\frac{ \sum_{i=1}^{k-1} \binom{M}{i-1}}{Ctot})\right)} \label{Fun3}
\end{eqnarray}
Written this way, the terms of the sum in \eqref{Fun3} are independent. So we can calculate each one of them in parallel.

\subsubsection*{Implementation}

We use MPI to implement the parallel version of the algorithm. We set as "master" one of the processes. It will gather all the calculation results from the other processes and compute them to obtain the final result. For each time $t$ of the input data, we run the parallel algorithm. The master is the only process that knows the input. Therefore the first step is to broadcast the $t$ to all the processes. Then the algorithm is made of two major steps :

\begin{itemize}

\item the calculation of $sum$. This expression contains $Ntr$ terms. Therefore each process calculates $\lfloor \frac{Ntr}{N_p}�\rfloor$ terms, and then we perform a reduce operation and the master gets the sum of all the terms. Concretely, after the calculation of one term by the processes, we perform a reduce operation and the master saves a partial sum, which it updates at each step. If $Ntr$ is not divisible by $N_p$, the master calculates the remaining terms of the sum. 

\item the calculation of $Fun$. It contains $M+1$ terms, then in the same way as for $sum$ the processes evaluates $\lfloor \frac{M+1}{N_p}�\rfloor$ terms of the sum. Afterwards the MPI program does a reduce operation and the master gets the total sum. It also deals with remaining terms if $M+1$ is not divisible by $N_p$.

\end{itemize}

Finally, the master returns the value of $Fun$, and the operation is repeated for all the input. 

\subsubsection{Chunked method}
The previous method performed a parallel calculation for each data point of the input. The chunked method does otherwise. It runs in parallel the sequential algorithm for different data points. We call $N_{input}$ the size of the input. The chunked method also uses a process as master, and is divided into three parts: 

\begin{itemize}

\item First the master, which is the only process knowing the input, allocates the amount of data to treat between all the processes. Each process has to compute the algorithm on a chunk of $\lfloor \frac{N_{input}}{N_p} \rfloor$ points. Therefore the master scatters the input points to the processes. 

\item Then each process runs the sequential algorithm on the chunk of points that it has to process by calling the operator of \verb_SeqLaplaceInv_. 

\item Afterwards, we do a gather to put all the results into a vector on the master. Then the masters deals with the remaining points if $N_{input}$ is not divisible by $N_p$, computing the sequential algorithm on them. Finally it returns the output vector. 

\end{itemize}

\subsection{Parallel OpenMP algorithm}

\newpage

\appendix
\section*{Problems encountered with the MPI integration}

\newpage

\begin{figure}[!h]
\includegraphics[width=7cm]{bt.jpg}
\end{figure}

\raggedleft
Nerd's and Geeks Office\\
MI6 Building\\
85 Albert Embankment\\
London SE1\\

\raggedright
\vspace{1cm}
\Huge{\textbf{Telephone Bill}}

\vspace{1cm}

\normalsize

\begin{tabularx}{\textwidth}{X X X}
  Number & Duration & Price \\
  \hline
  0700 0036 & 0h2m58s & \pounds458.92 \\
  \hline
  \textbf{Total w/o VAT} &  & \pounds458.92 \\
  \hline
  VAT 20\% & & \pounds91.78 \\
  \hline
  \textbf{Total with VAT} & & \pounds550.70 \\
\end{tabularx}


\end{document}
